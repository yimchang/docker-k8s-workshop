# 로깅과 모니터링

## 로깅

### 클러스터 레벨 로깅 원리

도커 컨테이너를 실행하고 로그를 확인하기 위해서 다음과 같은 명령을 사용합니다.

```bash
docker logs <CONTAINER_ID>
```

도커 컨테이너의 로그는 호스트 서버의 특정 디렉토리에 저장이 됩니다. 사용자는 직접 호스트 서버의 디렉토리를 찾아가 로그를 확인할 수도 있습니다. 호스트 서버의 디렉토리 위치는 다음과 같습니다.

```bash
/var/lib/docker/containers/<CONTAINER_ID>/<CONTAINER_ID>-json.log
```

---

**![주의](warning.png) 주의** 호스트 서버의 OS마다 혹은 컨테이너 런타임마다 컨테이너 로그가 저장되는 위치가 조금씩 다를 수 있습니다. 예제의 위치는 Ubuntu 20.04, k3s 쿠버네티스, 도커 컨테이너 런타임을 기준으로 작성하였습니다.

---

직접 호스트 서버의 로그 기록을 확인해 봅시다.

```bash
# nginx라는 컨테이너를 하나 실행하고 CONTAINER_ID 값을 복사합니다.
docker run -d nginx
# 4373b7e095215c23057b1dc4423527239e56a33dbd

# docker 명령을 통한 로그 확인
docker logs 4373b7e095215c23057b1dc4423527239e56a33dbd
# /docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will ...
# /docker-entrypoint.sh: Looking for shell scripts in /docker-...
# /docker-entrypoint.sh: Launching /docker-entrypoint.d/...
# ...

# 호스트 서버의 로그 파일 확인
sudo tail /var/lib/docker/containers/4373b7e095215c23057b1dc4423527239e56a33dbd/4373b7e095215c23057b1dc4423527239e56a33dbd-json.log
# {"log":"/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, \
# will attempt to perform configuration\n","stream":"stdout",\
# "time":"2020-07-11T03:22:11.817939191Z"}
# ...

# 컨테이너 정리
docker stop 4373b7e095215c23057b1dc4423527239e56a33dbd
docker rm 4373b7e095215c23057b1dc4423527239e56a33dbd
```

예제를 통해 알 수 있듯이 모든 컨테이너의 로깅 정보가 호스트의 특정 디렉토리에 저장됩니다. 로깅 수집기가 해당 디렉토리에 있는 정보를 수집하여 중앙 로그 저장소로 보내기만 하면 되므로, 쉽게 클러스터 레벨의 로깅 시스템을 구축할 수 있습니다.

### ElasticSearch

엘라스틱서치는 텍스트 검색에 최적화된 오픈소스 검색엔진입니다. 많은 양의 데이터를 손쉽게 쿼리할 수 있게 제공해주고, 확장성이 좋습니다. 엘라스틱서치는 구조적인 테이블 대신 JSON 형식으로 데이터를 저장하기 때문에 비정형 데이터를 저장하고 검색하는데 유리합니다. 또한 JSON 문서를 파싱하고 인덱싱하여 저장하기 때문에 굉장히 빠르게 검색을 수행합니다. 엘라스틱서치는 클러스터로 구성하여 확장성을 높힐 수 있습니다. EFK 스택에서 엘라스틱서치를 로그 저장소로 이용합니다.

### fluent-bit

일반적으로 EFK 스택이라고 할 때 `F`는 Fluentd를 가리킵니다. 그러나 예제에서는 `fluentd`의 경량 버전인 `fluent-bit`를 사용합니다. `fluent-bit`는 데이터 수집, 처리, 라우팅에 뛰어난 `fluentd`의 경량 버전 수집기입니다. `fluentd`는 로그를 수집하고 집계 (aggregation) 합니다. 또한, 여러 소스로부터 데이터를 수집하여 처리하고 또 다른 타겟으로 라우팅할 수 있도록 설계되었습니다. 그리고 대량의 데이터를 문제없이 처리하기 위해 뛰어난 성능의 큐를 가지고 있습니다. 또한, 많은 플러그인들을 지원하고 있어 손쉽게 다른 시스템과 연동할 수 있습니다.

`fluent-bit`도 로그를 수집 & 처리하고 다른 곳으로 데이터를 전달하는 반면, 데이터를 집계하는(aggregation) 기능은 없습니다. `fluent-bit`는 분산 환경에서 적은 리소스를 가지고도 빠르게 데이터를 타겟 시스템에 전달하는 것을 목표로 설계되었기 때문입니다. `fluent-bit`는 애초부터 컨테이너 환경을 염두해 두고 그곳에 맞게 최적의 성능을 내도록 만들어졌습니다. `fluent-bit`도 플러그인이 존재하지만 `fluentd`에 비해 에코 시스템이 작습니다. 하지만 쿠버네티스를 사용하는 경우 로그의 output 형식이 동일함으로 큰 문제가 되지 않습니다. 모든 `Pod`의 로그파일이 `/var/log/containers/*.log`에 생성되어 해당 로그 위치의 파일들만 수집하여 `elastic-search`로 전달하면 모든 컨테이너에 대해서 로깅을 수행할 수 있기 때문입니다.

![[그림 14-1] fluent-bit](https://github.com/hongkunyoo/handson-k8s/raw/master/14-logmon/14-01.png)

### Kibana

`Kibana`는 웹을 통해 dashboard를 제공하는 데이터 시각화 플랫폼입니다. 엘라스틱서치에 보관되어 있는 데이터들을 조회하여 다양한 visual 컴포넌트로 표현합니다. `Kibana`는 `KQL`(Kibana Query Language)라는 질의 언어를 따로 제공하여 `Kibana` 플랫폼에서 `elastic-search`로 퀴리할 수 있습니다. `Kibana`를 통해 사용자들은 바 차트, 플롯, 파이 차트, 맵과 같은 컴포넌트들을 이용하여 대용량 데이터에 대해서 손쉽게 시각화할 수 있습니다. `Kibana`는 Eastic Stack에서 시각적 인터페이스를 담당합니다.

![[그림 14-2] kibana (출처: [https://www.elastic.co](https://www.elastic.co))](https://github.com/hongkunyoo/handson-k8s/raw/master/14-logmon/14-02.png)

### EFK Stack

지금까지 살펴본 수집(`fluent-bit`), 저장(`elastic-search`), 시각화(`kibana`) 툴을 조합하여 EFK Stack을 구성할 수 있습니다. 원래 EFK 스택을 조합하기 위해서는 컴포넌트마다 설정값들을 서로 연결하여 하나의 스택을 구성해야 합니다. 다행히 helm chart 중에 EFK stack을 손쉽게 구성할 수 있는 `elastic-stack` chart를 제공합니다.

![[그림 14-3] EFK stack](14-03.png)

stable 레포지토리에서 `elastic-stack` 차트를 가져옵니다.

```bash
# fetch stable repository의 elastic-stack
helm fetch --untar stable/elastic-stack --version 2.0.1

vim elastic-stack/values.yaml
```

기본 수집기로 설정된 `logstash`를 비활성화하고 예제에서 사용할 `fluent-bit`를 활성화 합니다.

```yaml
# elastic-stack/values.yaml

# 약 12줄
logstash:
  enabled: false  # 기존 true

# 약 29줄
fluent-bit:
  enabled: true   # 기존 false
```

리소스 사용량을 최소화하기 위해 `elastic-search`의 `replicas`를 1개씩 줄여줍니다.

```bash
# elasticsearch 수정
vim elastic-stack/charts/elasticsearch/values.yaml
```

```yaml
# elastic-stack/charts/elasticsearch/values.yaml
# ...
# 약 110줄
client:
  replicas: 1  # 기존 2
# ...
# 약 171줄
master:
  replicas: 2  # 기존 3
# ...
# 약 225줄
data:
  replicas: 1  # 기존 2
```

---

**![참고](info.png) 참고** 사용하는 서버의 리소스가 충분히 많을 경우 replicas를 줄일 필요가 없습니다.

---

`fluent-bit`가 수집한 로그를 전달할 타겟 시스템을 수정합니다. 기존에 `fluentd`로 포워딩하는 것을 직접 `elastic-search`(`es`)로 변경합니다. 이때 사용할 호스트명으로 `efk-elasticsearch-client`를 입력합니다. 그 다음으로 로그를 수집할 위치를 지정합니다. `input` property의 `tail` 부분을 보면 앞서 설명 드린 바와 같이 `/var/log/containers/*.log`를 바라보고 docker 형식으로 파싱하는 것을 확인할 수 있습니다. 컨테이너 뿐만 아니라 시스템 로그(systemd)도 수집할 수 있습니다. `kubeadm` 툴을 이용하는 경우 `kubelet.service`의 로그를 가져오지만 `k3s`를 이용하여 쿠버네티스를 구축한 경우, `k3s.service` 로그를 가져올 수 있게 수정합니다.

```bash
# fluent-bit 수정
vim elastic-stack/charts/fluent-bit/values.yaml
```

```yaml
# elastic-stack/charts/fluent-bit/values.yaml
# ...
# 약 45줄
backend:
  type: es    # 기존 forward
  # ...
  es:
    host: efk-elasticsearch-client   # 기존 elasticsearch -> host 변경

# ...

# 약 226줄
input:
  tail:
    memBufLimit: 5MB
    parser: docker
    path: /var/log/containers/*.log
    ignore_older: ""
  systemd:
    enabled: true   # 기존 false
    filters:
      systemdUnit:
        - docker.service
        - k3.service    # 기존 kubelet.service
        # - node-problem-detector.service  --> 주석처리
```

---

`elastic-stach` 차트를 생성합니다. 이때 helm chart의 이름을 꼭 `efk`라고 지정해야 합니다. 백엔드 엘라스틱서치의 호스트명으로 `efk-elasticsearch-client`를 사용했기 때문입니다.

```bash
helm install efk ./elastic-stack
# NAME: efk
# LAST DEPLOYED: Sat Jul 11 07:17:06 2020
# NAMESPACE: default
# STATUS: deployed
# REVISION: 1
# NOTES:
# The elasticsearch cluster and associated extras have been installed.
# Kibana can be accessed:
# ...

# 모든 Pod가 다 실행되기까지 wait
watch kubectl get pod,svc
```

kibana로 접속하여 다음과 같은 작업을 수행합니다.

![[그림 14-4] index 생성](https://github.com/hongkunyoo/handson-k8s/raw/master/14-logmon/14-04.png)

1. `Explore on my own` 클릭
2. 왼쪽 패널 `Discover` 클릭
3. Index pattern에 `kubernetes_cluster-*` 입력 > Next step
4. Time Filter field name에 `@timestamp` 선택 > Create index pattern
5. 다시 `Discover` 패널로 가면 `Pod`들의 로그들을 볼 수 있습니다.

생성된 index를 통해 `Pod`들의 로그가 쌓이는 것을 확인할 수 있습니다. 단순히 로그 메세지가 저장되는 것 이외에 다양한 메타데이터 (라벨, 네임스페이스 등)가 자동으로 저장되어 정밀한 로그 검색이 가능합니다.

helm을 이용하여 클러스터 레벨의 로깅 시스템인 EFK 스택을 구축하는 방법에 대해서 살펴 보았습니다. 다음으로 리소스 사용량을 모니터링하는 시스템에 대해서 살펴보도록 하겠습니다.

### Clean up

```bash
helm delete efk
```

## 리소스 모니터링

안정적으로 서비스를 운영하기 위해 리소스 모니터링은 중요한 역할을 합니다. 쿠버네티스 위에서 동작하는 앱들은 기존과 다른 방식으로 동작합니다. 기존에는 각 서버에 특정 역할(웹 서버, 어플리케이션 서버 등)이 고정되어 있었고 그 역할에 맞는 모니터링 툴을 설치하여 모니터링 시스템으로 전달하였습니다. 이러한 역할을 수행하는 프로그램을 주로 모니터링 agent라 부르며 모니터링 시스템으로 정보를 전송(push) 하였습니다.

그렇지만 쿠버네티스 환경에서는 특정 서버라는 경계가 모호해지고 어플리케이션 단위로 모니터링 대상이 세밀해졌습니다. 또한, 어플리케이션이 배치되는 노드를 특정할 수 없고 그 개수도 고정되어 있지 않고 자주 바뀔 수 있게 되었습니다. 이러한 특성으로, 쿠버네티스 환경에서는 모니터링 agent를 설치하여 agent가 메트릭을 모니터링 시스템에 전달하는 방식(push-based)보다는 모니터링 시스템이 수집해야하는 대상을 찾아(discover) 직접 메트릭을 수집(pull-based)합니다. 쿠버네티스 환경에 맞게 만들어진 모니터링 시스템인 프로메테우스(Prometheus)에 대해 살펴 보겠습니다.

### Prometheus

프로메테우스는 SoundCloud사에서 만든 오픈소스 모니터링 및 알람 툴입니다. CNCF 재단의 2번째 프로젝트로 등록되었었고 지금은 졸업(graduated)한 프로젝트가 되었습니다. 프로메테우스는 service discovery로부터 수집 대상을 질의하여 직접 메트릭을 수집하는 pull-based 모니터링 툴입니다. 프로메테우스는 다음과 같은 특징을 가지고 있습니다.

### 컨테이너 메트릭 정보 수집 방법

실행된 도커 컨테이너의 프로세스 메트릭 정보를 얻기 위해서 다음과 같은 명령을 사용합니다.

```bash
docker run -d nginx
# 4373b7e095215c23057b1dc4423527239e56a33dbd

docker stats 4373b7e095215c23057b1dc4423527239e56a33dbd
# CONTAINER ID    NAME     CPU %     MEM USAGE / LIMIT     MEM    ...    
# 4af9f73eb06f    dreamy   0.00%     3.227MiB / 7.773GiB   0.04%  ...

docker stop 4373b7e095215c23057b1dc4423527239e56a33dbd
docker rm 4373b7e095215c23057b1dc4423527239e56a33dbd
```

`stats`라는 명령을 통해 사용자는 컨테이너의 리소스 사용량 정보를 확인할 수 있습니다. `exporter`는 이와 유사한 방법으로 메트릭 정보를 컨테이너로부터 추출하고 프로메테우스 서버가 메트릭 수집을 위해 `exporter`에게 요청을 하게 되면 추출한 메트릭 정보를 전달해 줍니다. 프로메테우스 서버는 수집한 메트릭 정보를 내부 저장소에 저장해 놓고 grafana와 같은 시각화 도구를 통해 결과를 보여줍니다.

### Prometheus & Grafana 구축

프로메테우스도 마찬가지로 각종 컴포넌트들을 직접 연결해서 사용해야 하지만 Prometheus도 이미 잘 정리된 helm chart가 존재합니다. stable 레포지토리의 `prometheus-operator`를 이용하여 손쉽게 리소스 모니터링 시스템을 구축해보겠습니다.

```bash
helm install mon stable/prometheus-operator --version 8.16.1
# manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
# manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
# manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
# manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
# manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
# manifest_sorter.go:192: info: skipping unknown hook: "crd-install"
# NAME: mon
# LAST DEPLOYED: Thu Jul 16 08:44:38 2020
# ...

watch kubectl get pod
```

웹 브라우저를 통해 grafana를 접근합니다.

- `username`: admin
- `password`: prom-operator

### Clean up

```bash
helm delete mon
```